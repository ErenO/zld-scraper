{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras import backend as K\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n",
    "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import functools\n",
    "import cv2 as cv\n",
    "%pylab inline\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/'\n",
    "dataset = []\n",
    "tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, subdirs, files in os.walk(path):\n",
    "    for name in files:\n",
    "        file_path = os.path.join(path, name)\n",
    "        dataset.append(file_path)\n",
    "        for cls in classes:\n",
    "            if (cls in file_path):\n",
    "                tags.append(cls)\n",
    "                break;\n",
    "#         print (os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['pull', 'veste', 't-shirts', 'sweatshirts', 'manteaux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "# shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset/veste/veste87.jpg', 'dataset/veste/veste223.jpg', 'dataset/veste/veste643.jpg', 'dataset/veste/veste1527.jpg', 'dataset/veste/veste1181.jpg', 'dataset/veste/veste445.jpg', 'dataset/veste/veste1685.jpg', 'dataset/veste/veste536.jpg', 'dataset/veste/veste615.jpg', 'dataset/veste/veste202.jpg', 'dataset/veste/veste314.jpg', 'dataset/veste/veste1057.jpg', 'dataset/veste/veste644.jpg', 'dataset/veste/veste1614.jpg', 'dataset/veste/veste197.jpg', 'dataset/veste/veste1680.jpg', 'dataset/veste/veste1308.jpg', 'dataset/veste/veste337.jpg', 'dataset/veste/veste718.jpg', 'dataset/veste/veste962.jpg', 'dataset/veste/veste1267.jpg', 'dataset/veste/veste1810.jpg', 'dataset/veste/veste1482.jpg', 'dataset/veste/veste1295.jpg', 'dataset/veste/veste186.jpg', 'dataset/veste/veste1012.jpg', 'dataset/veste/veste1631.jpg', 'dataset/veste/veste1024.jpg', 'dataset/veste/veste1093.jpg', 'dataset/veste/veste45.jpg', 'dataset/veste/veste1502.jpg', 'dataset/veste/veste1654.jpg', 'dataset/veste/veste225.jpg', 'dataset/veste/veste1612.jpg', 'dataset/veste/veste1523.jpg', 'dataset/veste/veste574.jpg', 'dataset/veste/veste480.jpg', 'dataset/veste/veste1735.jpg', 'dataset/veste/veste1191.jpg', 'dataset/veste/veste743.jpg', 'dataset/veste/veste1625.jpg', 'dataset/veste/veste278.jpg', 'dataset/veste/veste636.jpg', 'dataset/veste/veste629.jpg', 'dataset/veste/veste1814.jpg', 'dataset/veste/veste1330.jpg', 'dataset/veste/veste1183.jpg', 'dataset/veste/veste1668.jpg', 'dataset/veste/veste917.jpg', 'dataset/veste/veste400.jpg', 'dataset/veste/veste56.jpg', 'dataset/veste/veste514.jpg', 'dataset/veste/veste1540.jpg', 'dataset/veste/veste78.jpg', 'dataset/veste/veste397.jpg', 'dataset/veste/veste203.jpg', 'dataset/veste/veste1661.jpg', 'dataset/veste/veste1244.jpg', 'dataset/veste/veste780.jpg', 'dataset/veste/veste1200.jpg', 'dataset/veste/veste80.jpg', 'dataset/veste/veste1848.jpg', 'dataset/veste/veste677.jpg', 'dataset/veste/veste120.jpg', 'dataset/veste/veste335.jpg', 'dataset/veste/veste1812.jpg', 'dataset/veste/veste986.jpg', 'dataset/veste/veste918.jpg', 'dataset/veste/veste113.jpg', 'dataset/veste/veste1454.jpg', 'dataset/veste/veste908.jpg', 'dataset/veste/veste654.jpg', 'dataset/veste/veste794.jpg', 'dataset/veste/veste1098.jpg', 'dataset/veste/veste149.jpg', 'dataset/veste/veste1422.jpg', 'dataset/veste/veste1441.jpg', 'dataset/veste/veste22.jpg', 'dataset/veste/veste349.jpg', 'dataset/veste/veste749.jpg', 'dataset/veste/veste346.jpg', 'dataset/veste/veste205.jpg', 'dataset/veste/veste490.jpg', 'dataset/veste/veste1491.jpg', 'dataset/veste/veste675.jpg', 'dataset/veste/veste133.jpg', 'dataset/veste/veste521.jpg', 'dataset/veste/veste1826.jpg', 'dataset/veste/veste1708.jpg', 'dataset/veste/veste1706.jpg', 'dataset/veste/veste1494.jpg', 'dataset/veste/veste1218.jpg', 'dataset/veste/veste673.jpg', 'dataset/veste/veste1760.jpg', 'dataset/veste/veste63.jpg', 'dataset/veste/veste1694.jpg', 'dataset/veste/veste24.jpg', 'dataset/veste/veste275.jpg', 'dataset/veste/veste989.jpg', 'dataset/veste/veste1376.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(dataset,\n",
    "                                                      tags,\n",
    "                                                      test_size=0.1,\n",
    "                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes_train = [0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in y_train:\n",
    "    nb_classes_train[classes.index(cls)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes_test = [0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in y_test:\n",
    "    nb_classes_test[classes.index(cls)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1674, 1669, 1654, 1678, 1667]\n"
     ]
    }
   ],
   "source": [
    "print (nb_classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179, 186, 200, 176, 186]\n"
     ]
    }
   ],
   "source": [
    "print (nb_classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
